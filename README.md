# Hyena_Hierarchy-
 ChatGPT said:Benchmark comparing Transformer self-attention (O(n²)) and Hyena convolution (O(n log n)) using PyTorch. Measures runtime across sequence lengths, visualizes scaling, and highlights Hyena’s efficiency in long-context processing. Demonstrates how FFT-based convolutions outperform traditional attention in scalability and performance.
